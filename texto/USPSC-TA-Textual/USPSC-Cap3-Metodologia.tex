
\chapter{Metodologia}\label{cap_metodologia}

Este capítulo detalha a metodologia de trabalho utilizada, apresentando o delineamento da pesquisa, da coleta e processamento dos dados e as técnicas analíticas empregadas para responder às perguntas de pesquisa. A estrutura metodológica adotada será baseada no modelo CRISP-DM (\textit{Cross-Industry Standard Process for Data Mining}) \cite{Chapman2000CRISPDM}, contendo as etapas de (i) entendimento de negócio, (ii) entendimento dos dados, (iii) preparação dos dados, (iv) modelagem, (v) avaliação e (vi) implantação.

\begin{figure}[H]
    \centering
    \caption{Modelo CRISP-DM}
    \includegraphics[width = 0.7\textwidth]{imagens/crisp-dm.png}
    \label{fig:crisp-dm}
\begin{center}
    \footnotesize Fonte: modificado de Chapman \textit{et al.} \cite{Chapman2000CRISPDM}.
\end{center}
\end{figure}

\section{Entendimento de Negócio}\label{entendimento_negocio}

O entendimento de negócio é a primeira etapa do modelo CRISP-DM e envolve a definição clara dos objetivos do projeto, a compreensão do contexto em que a pesquisa está inserida e a identificação das partes interessadas. O foco principal deste trabalho acadêmico será a formulação de hipóteses relacionadas aos fatores que influenciam o desempenho dos estudantes no ENEM, bem como a análise do ``Efeito Escola''.

Conforme já mencionado no Capítulo \ref{cap_fundamentacao} - Fundamentação Teórica, o ENEM é um exame de grande relevância no contexto educacional brasileiro e compreender os fatores que impactam o desempenho dos estudantes é crucial para a formulação de políticas educacionais eficazes. Trabalhos anteriores citam algumas variáveis socioeconômicas como discriminadores de performance no ENEM. A Tabela \ref{tab_variaveis_socioeconomicas} apresenta algumas dessas variáveis socioeconômicas identificadas na literatura, juntamente com suas respectivas referências.

\begin{table}[h]

    \centering

    \caption{Variáveis socioeconômicas e suas referências}

    \begin{tabular}{|m{7cm}|m{4cm}|} \hline

        \textbf{Variável socioeconômica} & \textbf{Referência} \\ \hline
        Renda familiar & Melo \textit{et al.} \cite{ref_01} \\ & Vasconcellos \cite{ref_06} \\ \hline
        Raça / Cor & Melo \textit{et al.} \cite{ref_01} \\ & Moraes \textit{et al.} \cite{ref_03} \\ \hline
        Sexo & Moraes \textit{et al.} \cite{ref_03} \\ \hline
        Idade / Atraso Escolar & Jaloto e Primi \cite{ref_12} \\ \hline
        Administração: Pública vs. Privada & Moraes \textit{et al.} \cite{ref_03} \\ & Jaloto e Primi \cite{ref_12} \\ & Ortega \textit{et al.} \cite{ref_05} \\ \hline
        Atributos Escolares & Moraes \textit{et al.} \cite{ref_03} \\ \hline
    \end{tabular}

    \label{tab_variaveis_socioeconomicas}

    \begin{center}
        \footnotesize Fonte: elaborado pelo autor.
    \end{center}

\end{table}

Assim, para este trabalho, são formuladas as seguintes perguntas de pesquisa:

\begin{itemize}
    \item \textbf{Pergunta 1:} Quais são os principais fatores socioeconômicos que influenciam o desempenho dos estudantes no ENEM?
    \item \textbf{Pergunta 2:} Qual é a magnitude da influência de cada um desses conjuntos de fatores nas notas dos participantes?
\end{itemize}

Com as perguntas de pesquisa definidas, o próximo passo é compreender os dados disponíveis para análise, conforme descrito na Seção \ref{entendimento_dados}.

\section{Entendimento dos Dados}\label{entendimento_dados}

Nesta etapa, o foco será a coleta e compreensão dos dados disponíveis para análise. Utilizarei os microdados do ENEM como fonte principal e que são disponibilizados anualmente pelo Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira (INEP).

\subsection{Estrutura dos Dados}\label{estrutura_dados}

Os dados se encontram em arquivos CSV (\textit{Comma-Separated Values}) \cite{ref_08}, o que facilita a sua manipulação e análise. Os dados da edição de 2022 e 2023 possuem 76 variáveis e 3,4 milhões e 3,9 milhões de observações, respectivamente, onde cada observação é um candidato que se inscreveu para realizar o exame.

O dicionário de dados também é disponibilizado e descreve detalhadamente cada variável presente no conjunto de dados. A seguir, apresento um resumo do dicionário de dados.

\begin{itemize}

    \item \textbf{Dados do participante:} Número de inscrição mascarado, ano do exame, faixa etária, sexo, estado civil, cor/raça, nacionalidade, situação de conclusão do Ensino Médio, ano de conclusão do Ensino Médio, tipo de escola do Ensino Médio, tipo de instituição que concluiu ou concluirá o Ensino Médio e se o inscrito fez a prova como treineiro.

    \item \textbf{Dados da escola:} Código e nome da escola, código e sigla da Unidade da Federação, código do município, nome do município, dependência administrativa, localização e situação de funcionamento.

    \item \textbf{Dados do local de aplicação da prova:} Código e nome da escola onde a prova foi aplicada, código e sigla da Unidade da Federação, código do município e nome do município.

    \item \textbf{Dados das provas objetivas:} Presença e código do tipo de prova objetiva, nota das provas objetivas, vetor com as respostas, língua estrangeira escolhida e vetor com o gabarito.

    \item \textbf{Dados da redação: } Situação da redação (se o candidato apresentou fuga do tema, deixou em branco, copiou o texto motivador, entre outras), nota das cinco competências e nota final da prova de redação.

    \item \textbf{Dados do questionário socioeconômico:} Respostas do questionário socioeconômico aplicado aos participantes do ENEM.


\end{itemize}

A partir da interpretação do dicionario de dados, já é possível identificar diversas variáveis que podem ser utilizadas para responder às perguntas de pesquisa formuladas na Seção \ref{entendimento_negocio}, assim como as variáveis resposta.

\subsection{Definição da Variável Resposta}\label{definicao_variavel_resposta}

Para este trabalho, serão usadas as notas de cada prova objetiva do ENEM como variáveis resposta, ou seja, as variáveis que queremos prever com base nas outras variáveis disponíveis no conjunto de dados. As provas objetivas do ENEM são divididas em quatro áreas de conhecimento: (i) Ciências da Natureza, (ii) Ciências Humanas, (iii) Linguagens e Códigos e (iv) Matemática. Além disso, a prova do ENEM possui uma redação com nota própria e que também será considerada como uma variável resposta.

\section{Preparação do Ambiente Python}\label{preparacao_ambiente_python}

Para a execução desse trabalho, foi utilizado um ambiente virtual baseado em Miniconda3 \cite{Anaconda_Miniconda_nd}. Dado o volume grande de dados (mais de 7 milhões de observações, 3,1 GB), foi necessário utilizar uma GPU para acelerar o processamento dos dados e a modelagem. A GPU utilizada foi uma NVIDIA GeForce RTX 4070 Ti Super, com 16 GB de memória dedicada.

Para possibilitar essa execução, o ambiente foi especificamente configurado com o ecossistema NVIDIA CUDAX \cite{NVIDIA_CUDAX_nd}. Esta suíte de bibliotecas de software permite executar pipelines de Ciência de Dados e análises inteiramente na GPU, minimizando a transferência de dados entre a CPU e a GPU.

Foram utilizados seus principais componentes: \texttt{cudf} \cite{NVIDIA_cuDF_nd}, uma biblioteca para manipulação de \texttt{DataFrames} na GPU análoga ao \texttt{pandas} \cite{PandasTeam_PandasDocs_2025}, e \texttt{cuml} \cite{NVIDIA_cuML_2023}, que fornece implementações de algoritmos de \textit{Machine Learning} acelerados por GPU, análoga ao \texttt{scikit-learn} \cite{scikit-learn}. Todo o ambiente foi construído sobre a plataforma CUDA 13.0, com as bibliotecas e dependências gerenciadas diretamente pelo Conda.

O arquivo YML de configuração do ambiente virtual utilizado está disponível no Apêndice \ref{apendice_ambiente_virtual}.

\section{Preparação dos Dados}\label{preparacao_dados}

A preparação dos dados é uma etapa crucial no processo de análise, pois envolve a limpeza, transformação e integração dos dados para torná-los adequados para a modelagem. Nesta seção, detalharei as etapas realizadas para preparar os microdados do ENEM para análise.

\subsection{Coleta, Leitura e Integração dos Dados}\label{coleta_integracao_dados}

A coleta dos dados foi realizada por meio do download dos arquivos CSV disponibilizados pelo INEP para as edições de 2022 e 2023 do ENEM. Os arquivos foram armazenados localmente para facilitar o acesso durante o processo de análise.

A leitura dos dados foi feita utilizando o método \texttt{read\_csv}, da biblioteca \texttt{cudf}, especificando o separador como ponto e vírgula (\texttt{sep = ';'}).

Os conjuntos de dados do ENEM de 2022 e 2023 possuem o mesmo esquema, ou seja, as mesmas variáveis estão presentes em ambas as edições e com o mesmo nome. Portanto, a integração foi realizada por meio da concatenação vertical dos dois conjuntos de dados, utilizando o método \texttt{concat} da biblioteca \texttt{cudf}.

Em seguida, foi feita uma modificação no nome das variáveis para nomes que fossem mais intuitivos e de compreensão rápida do conteúdo. Essa modificação foi realizada utilizando o método \texttt{rename}, a partir de um dicionário que mapeava os nomes originais para os novos nomes desejados.

\subsection{Exploração Inicial}\label{exploracao_inicial}

Com os dados no formato desejado, foi realizada uma exploração inicial para compreender a estrutura dos dados, identificar valores ausentes e detectar possíveis inconsistências.

Foram analisadas as cinco variáveis respostas selecionadas com a variável de presença respectiva para entender a relação de notas nulas/zero com a ausência do participante na prova. Para a nota da redação, foi utilizada a variável de presença na prova de Linguagens e Códigos, que é quando a redação é aplicada, juntamente com a variável de status da redação, que indica se a redação foi anulada ou não.

Como iremos realizar a análise considerando cada variável resposta separadamente, foram criados cinco conjuntos de dados distintos, um para cada variável resposta, a partir da análise feita anteriormente.

Foram selecionadas apenas as observações que possuem presença nas provas correspondentes e tiveram nota válida (diferente de nulo ou zero) para cada variável resposta. Para a redação, além da presença na prova, também foram removidas as observações com redações com problemas.

\subsection{Tratamento de Valores Ausentes}\label{tratamento_valores_ausentes}

Para a avaliação e tratamento de valores ausentes, foi necessário fazer um tratamento inicial para identificar os valores que representam ausência de dados em cada variável.

No conjunto de dados do ENEM, alguns valores ausentes são representados por códigos específicos, como \texttt{0}. Para essas variáveis, foi feita a substituição desses códigos por \texttt{None} e os demais códigos por valores apropriados (já pensando num futuro \textit{One-Hot Encoding}), através de um dicionário e o método \texttt{map}. Em seguida, foi utilizado o método \texttt{isnull} para identificar os valores ausentes em cada variável.

Para variáveis que apresentaram uma alta proporção de valores ausentes, foi decidido removê-las do conjunto de dados, pois a quantidade de informações perdidas poderia comprometer a análise. Para as demais variáveis, foi adotada uma estratégia específica de imputação de valores ausentes, que será detalhada na Seção \ref{imputacao_valores_ausentes}.

\subsection{Transformação de Variáveis Categóricas}\label{transformacao_variaveis_categoricas}

Algumas variáveis categóricas são representadas com números inteiros, o que poderia levar os modelos de \textit{Machine Learning} a interpretá-las como variáveis numéricas ordinais. Para evitar esse problema, foi feita a substituição dos códigos numéricos por rótulos textuais mais descritivos, utilizando o método \texttt{map} com um dicionário de mapeamento. Em seguida, foi aplicado o \textit{One-Hot Encoding} para transformar essas variáveis categóricas em variáveis binárias, utilizando o método \texttt{OneHotEncoder} da biblioteca \texttt{sklearn.preprocessing}.

\section{Análise de correlação das Variáveis Preditoras}\label{analise_correlacao_variaveis}

Antes de iniciar a modelagem, foi realizada uma análise de correlação entre as variáveis preditoras para identificar possíveis multicolinearidades que poderiam afetar o desempenho dos modelos. A correlação foi avaliada utilizando a biblioteca \texttt{phik} \cite{KPMG_PhiK_2024} \cite{Baak2020Phik}, que permite calcular a correlação entre variáveis categóricas e numéricas.

\subsection{Imputação de Valores Ausentes}\label{imputacao_valores_ausentes}

Para as variáveis com valores ausentes que não foram removidas, foi adotado o método de \textit{KNN Imputer}, que utiliza a média/moda dos \textit{k} vizinhos mais próximos para preencher os valores ausentes. Esse método foi escolhido por sua capacidade de preservar a distribuição dos dados e considerar a correlação entre as variáveis.

O \textit{KNN Imputer} foi implementado utilizando a classe \texttt{KNNImputer} da biblioteca \texttt{sklearn.impute}. Para se determinar o hiperparâmetro \texttt{k}, foi feita uma rápida análise de sensibilidade, testando diferentes valores de \texttt{k} e avaliando o impacto na distribuição das variáveis imputadas e na performance dos modelos preditivos. Para cada variável a ser imputada, foi selecionado o valor de \texttt{k} que apresentou o melhor equilíbrio entre acurácia e estabilidade.

\section{Modelagem}\label{modelagem}

A modelagem é a etapa onde os dados preparados são utilizados para construir modelos preditivos que possam responder às perguntas de pesquisa formuladas na Seção \ref{entendimento_negocio}. Nesta seção, serão detalhadas as técnicas de modelagem empregadas e os critérios utilizados para a seleção dos modelos.

\subsection{Seleção de Modelos}\label{selecao_modelos}

Como as nossas variáveis respostas são numéricas e contínuas, estamos em um problema de regressão de aprendizado supervisionado. Assim, é preciso selecionar modelos de regressão, que são os adequados para prever variáveis contínuas. Os modelos escolhidos foram a Regressão Linear com Regularizações (como \textit{benchmark}) e o XGBoost Regressor \cite{XGBoostDevelopers_Tutorials_2025}, ambos amplamente utilizados devido à sua eficácia e interpretabilidade.

\subsection{Otimização dos Hiperparâmetros}\label{otimizacao_hiperparametros}

Para otimizar o desempenho dos modelos selecionados, foi realizada uma busca em grade (\textit{Grid Search}) para identificar os melhores hiperparâmetros. A busca foi realizada utilizando validação cruzada para garantir que os resultados fossem robustos e generalizáveis.

\subsection{Treino dos Modelos}\label{treino_modelos}

Definidos os hiperparâmetros ótimos, os modelos foram treinados utilizando o conjunto de dados preparado na Seção \ref{preparacao_dados}. O treinamento foi realizado em validação cruzada de cinco \textit{folds}, utilizando a biblioteca \texttt{cuml} para se beneficiar da aceleração por GPU. Foi selecionado como modelo final aquele modelo que apresentou o melhor desempenho médio nos \textit{folds} de validação para cada variável resposta.

\subsection{Avaliação dos Modelos}\label{avaliacao_modelos}

A avaliação dos modelos foi realizada utilizando métricas de desempenho apropriadas para problemas de regressão, como a Raiz do Erro Quadrático Médio (RMSE) e o Coeficiente de Determinação (R²). Essas métricas fornecem uma visão clara da precisão das previsões dos modelos em relação aos valores reais das notas do ENEM.

Também foram realizadas análises de resíduos para verificar a adequação dos modelos e identificar possíveis padrões não capturados pelas previsões, bem como a análise gráfica das previsões versus os valores reais para avaliar visualmente o desempenho dos modelos.

\section{Magnitude da Influência das Variáveis Preditoras}\label{medicao_efeito_variaveis}

Para medir o efeito de cada variável preditora nas notas do ENEM, foram utilizadas técnicas de interpretação de modelos, que permitem identificar quais variáveis têm maior impacto nas previsões dos modelos e como elas influenciam as notas dos estudantes. Entre as técnicas empregadas estão a importância das características (\textit{feature importance}), a análise dos valores SHAP (\textit{SHapley Additive exPlanations}) e os gráficos de dependência parcial (\textit{partial dependence plots}).

Além disso, foi realizada uma análise de sensibilidade para avaliar como mudanças nas variáveis preditoras afetam as previsões dos modelos. Para isso, foi construída uma matriz de cenários hipotéticos, onde cada variável preditora é alterada sistematicamente enquanto as outras são mantidas constantes. As previsões resultantes foram então analisadas para quantificar o impacto de cada variável nas notas do ENEM.

\section{Limitações e Considerações Éticas}\label{limitacoes_eticas}

Algumas limitações devem ser destacadas. Primeiro, apesar do grande volume de dados, a presença de vieses de seleção (por exemplo, diferença entre participantes regulares e treineiros, ou entre ausentes e presentes nas provas) pode influenciar as inferências; as análises procuram mitigar esses efeitos, mas não os eliminam completamente. Segundo, variáveis censuradas, inconsistências de registro e códigos especiais para ausência exigiram tratamentos que podem introduzir perdas de informação.

Quanto às considerações éticas, todos os dados utilizados são microdados públicos disponibilizados pelo INEP, já anonimizados para preservar a privacidade dos participantes. Recomenda-se cautela na interpretação dos resultados para evitar conclusões simplistas sobre individualidades dos estudantes ou estigmatização de grupos e instituições.

No Capítulo \ref{cap_resultados} serão apresentados os resultados empíricos da metodologia empregada: (i) a descrição dos dados após o pré-processamento, (ii) a análise de correlação entre as variáveis preditoras, (iii) o desempenho dos modelos preditivos na previsão das notas do ENEM, e (iv) a análise da magnitude da influência das variáveis preditoras nas notas dos estudantes.