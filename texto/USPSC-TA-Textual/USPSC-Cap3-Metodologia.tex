
\chapter{Metodologia}\label{cap_metodologia}

Este capítulo detalha a metodologia de trabalho utilizada, apresentando o delineamento da pesquisa, da coleta e processamento dos dados e as técnicas analíticas empregadas para responder às perguntas de pesquisa.

A estrutura metodológica adotada será baseada no modelo CRISP-DM (\textit{Cross-Industry Standard Process for Data Mining}) \cite{Chapman2000CRISPDM}, contendo as etapas de (i) entendimento de negócio, (ii) entendimento dos dados, (iii) preparação dos dados, (iv) modelagem, (v) avaliação e (vi) implantação.

\begin{figure}[H]
    \centering
    \caption{Modelo CRISP-DM}
    \includegraphics[width = 0.7\textwidth]{imagens/crisp-dm.png}
    \label{fig:crisp-dm}
    \par\vspace{0.1cm}
    \footnotesize Fonte: modificado de Chapman \textit{et al.} \cite{Chapman2000CRISPDM}.
\end{figure}

\section{Entendimento de Negócio}\label{metodologia_entendimento_negocio}

A etapa de entendimento de negócio envolve a definição clara dos objetivos do projeto, a compreensão do contexto em que a pesquisa está inserida, a identificação das partes interessadas, a formulação das perguntas de pesquisa que guiarão a análise dos dados e os resultados que espera-se alcançar.

Como o foco principal deste trabalho será a formulação de hipóteses relacionadas aos fatores que influenciam o desempenho dos estudantes no ENEM, através da análise dos dados de performance dos participantes e suas características socioeconômicas,  foi necessário formular perguntas de pesquisa específicas que possam ser respondidas através da análise dos dados disponíveis.

\section{Entendimento dos dados}\label{metodologia_entendimento_dados}

Com as perguntas de pesquisa definidas, a próxima etapa foi encontrar dados que fossem adequados para responder a essas perguntas e estabelecer uma forma consistente de coleta e armazenamento desses dados para em seguida realizar uma compreensão de sua estrutura e significado.

Após essa etapa, foi possível identifcar quais os arquivos são relevantes para a análise e quais variáveis dentro desses arquivos serão utilizadas como variáveis preditoras e como variáveis resposta.

Há depender dos tipos de dados a serem utilizados, é necessário submeter o projeto a um comitê de ética em pesquisa para aprovação, garantindo que todos os aspectos éticos relacionados ao uso dos dados sejam devidamente considerados.

\section{Preparação dos dados}\label{metodologia_preparacao_dados}

Com os arquivos relevantes selecionados, passa-se para a etapa de preparação dos dados, que envolve a leitura, limpeza, transformação e integração dos dados para torná-los adequados para a modelagem. Essa etapa é crucial, pois a qualidade dos dados impacta diretamente na eficácia dos modelos preditivos que serão construídos posteriormente.

Para a execução dessa e das etapas posteriores, é necessário preparar um ambiente tecnológico e analítico adequado que permita a manipulação eficiente dos dados e a construção dos modelos preditivos.

Após a leitura dos dados, estes foram integrados em único conjunto de dados para facilitar a análise e a modelagem. Foram realizados os ajustes necessários no esquema dos dados para garantir a consistência e a integridade das informações.

Em seguida, as variáveis foram renomeadas para nomes mais intuitivos e de fácil compreensão e foi analisado se necessário transformar os valores das variáveis originais em valores mais compreensíveis, por exemplo, transformar os códigos numéricos de variáveis categóricas em rótulos textuais.

Posteriormente, foi realizada uma análise para identificar e tratar valores nulos, removendo ou imputando valores conforme apropriado. Após o tratamento dos valores nulos, os dados foram separados em diferentes conjuntos de dados, cada um correspondente a uma variável resposta específica, garantindo que cada conjunto contenha apenas as observações relevantes para a análise daquela variável e sem valores nulos.

\section{Modelagem}\label{metodologia_modelagem}

Com os dados preparados, a etapa de modelagem envolve a análise exploratória dos dados para entender suas características, avaliação de correlações entre as variáveis preditoras, seleção e treinamento dos modelos preditivos e otimização dos hiperparâmetros. Além disso, é importante medir a magnitude da influência das variáveis preditoras nas variáveis resposta, utilizando técnicas de interpretação de modelos e análise de sensibilidade.

\subsection{Análise Exploratória dos Dados}\label{metodologia_exploracao_dados}

A análise exploratória foi iniciada com o entendimento das variáveis respostas, buscando entender a distribuição das notas do ENEM. Em seguida, foi feito um teste de hipótese para se avaliar se as médias das notas variam significativamente entre as edições selecionadas para esse trabalho.

Esse análise é necessária uma vez que as edições do ENEM podem apresentar variações no nível de dificuldade das provas, impactando as notas dos estudantes. Para isso, será utilizada a Estatística F de ANOVA (\textit{Analysis of Variance}) \cite{bussab2017} para comparar as médias das notas entre as diferentes edições do ENEM e o cálculo do tamanho do efeito para quantificar a magnitude das diferenças encontradas, utilizando a métrica SMD (\textit{Standardized Mean Difference}) utilizando os intervalos definidos por Jacob Cohen \cite{cohen1988}.

A próxima etapa da análise exploratória foi a identificação de outliers nas variáveis respostas, utilizando o critério de 1.5 vezes o intervalo interquartil (IQR) \cite{bussab2017}. A identificação dos outliers é importante para entender a distribuição das notas e avaliar se esses valores extremos podem influenciar os resultados dos modelos preditivos.

Finalizadas as análises das variáveis respostas, foram realizadas três análises sobre as variáveis preditoras: (i) análise de concentração de categorias, (ii) análise de correlação entre as variáveis preditoras e (iii) cálculo do \textit{Permutation Importance} para cada variável preditora.

Utilizando essas três informações, foi feita uma análise qualitativa para identificar possíveis variáveis preditoras a serem removidas do conjunto de dados, seja por apresentarem baixa correlação com as variáveis respostas, por apresentarem alta correlação com outras variáveis preditoras (multicolinearidade) ou por apresentarem baixa importância na predição das notas do ENEM.

Para a correlação, foi utlizada a biblioteca \texttt{phik} \cite{KPMG_PhiK_2024} \cite{Baak2020Phik}, que permite calcular a correlação entre variáveis categóricas e numéricas, além de fornecer métricas para avaliar a força da correlação.

Para o cálculo do \textit{Permutation Importance}, foi utilizado o modelo de \textit{Random Forest Regressor} do \texttt{cuml} \cite{NVIDIA_cuML_2023} e o método de \textit{permutation importance} da biblioteca \texttt{sklearn} \cite{scikit-learn}. Foi necessário já separar os conjuntos de dados em treino e teste, afim de evitar vazamento de dados e garantir que a avaliação da importância das variáveis seja feita de forma justa e realista.

Para essa separação, foi utilizado o método \textit{train\_test\_split} da biblioteca \texttt{sklearn}, com uma proporção de 80\% dos dados para treino e 20\% para teste. A partir desse momento, não usamos mais o conjunto de dados completo, mas sim apenas o conjunto de treino para as análises das variáveis preditoras.

\section{Treinamento dos Modelos}\label{metodologia_treinamento_modelos}

Nesta seção serão detalhadas as técnicas de modelagem empregadas e os critérios utilizados para a seleção dos modelos. Como as nossas variáveis respostas são numéricas e contínuas, estamos em um problema de regressão de aprendizado supervisionado. Assim, é preciso selecionar modelos de regressão, que são os adequados para prever variáveis contínuas.

Usaremos três modelos de regressão: (i) \textit{Random Forest Regressor}, (ii) \textit{XGBoost Regressor} e (iii) \textit{LightGBM Regressor}. Esses modelos são amplamente utilizados devido à sua eficácia e interpretabilidade, além de serem capazes de lidar com grandes volumes de dados e variáveis preditoras.

Para otimizar o desempenho dos modelos selecionados, será realizada uma busca em grade (\textit{Grid Search}) para identificar os melhores hiperparâmetros. A busca não será realizada utilizando validação cruzada, devido ao alto volume de dados, mas sim um subconjunto do conjunto de treino equivalente a 10\% dos dados originais, garantindo que os resultados sejam robustos e generalizáveis.

A implementação da busca em grade será feita manualmente, utilizando loops para iterar sobre os diferentes valores dos hiperparâmetros e avaliando o desempenho dos modelos utilizando o conjunto de validação.  Isso se dá para evitar o alto custo computacional associado à utilização de bibliotecas como \texttt{GridSearchCV} da \texttt{sklearn}, que realizam a busca em grade utilizando validação cruzada, o que pode ser inviável para grandes volumes de dados e modelos complexos.

Definidos os hiperparâmetros ótimos, os modelos serão treinados utilizando o conjunto de dados preparado na Seção \ref{metodologia_preparacao_dados}, com uma quantidade maior de estimadores fracos (através do hiperparâmetro \textit{n\_estimators}) para garantir um melhor desempenho dos modelos. O treinamento será realizado utilizando o conjunto de treino completo, garantindo que os modelos sejam treinados com a maior quantidade possível de dados para melhorar sua capacidade de generalização.

\section{Avaliação}\label{metodologia_avaliacao}



\section{Implantação}\label{metodologia_implantacao}
















% \section{Análise de correlação das Variáveis Preditoras}\label{analise_correlacao_variaveis}

% Antes de iniciar a modelagem, foi realizada uma análise de correlação entre as variáveis preditoras para identificar possíveis multicolinearidades que poderiam afetar o desempenho dos modelos. A correlação foi avaliada utilizando a biblioteca \texttt{phik} \cite{KPMG_PhiK_2024} \cite{Baak2020Phik}, que permite calcular a correlação entre variáveis categóricas e numéricas.



% \section{Modelagem}\label{modelagem}

% A modelagem é a etapa onde os dados preparados são utilizados para construir modelos preditivos que possam responder às perguntas de pesquisa formuladas na Seção \ref{entendimento_negocio}. Nesta seção, serão detalhadas as técnicas de modelagem empregadas e os critérios utilizados para a seleção dos modelos.

% \subsection{Seleção de Modelos}\label{selecao_modelos}

% Como as nossas variáveis respostas são numéricas e contínuas, estamos em um problema de regressão de aprendizado supervisionado. Assim, é preciso selecionar modelos de regressão, que são os adequados para prever variáveis contínuas. Os modelos escolhidos foram a Regressão Linear com Regularizações (como \textit{benchmark}) e o XGBoost Regressor \cite{XGBoostDevelopers_Tutorials_2025}, ambos amplamente utilizados devido à sua eficácia e interpretabilidade.

% \subsection{Otimização dos Hiperparâmetros}\label{otimizacao_hiperparametros}

% Para otimizar o desempenho dos modelos selecionados, foi realizada uma busca em grade (\textit{Grid Search}) para identificar os melhores hiperparâmetros. A busca foi realizada utilizando validação cruzada para garantir que os resultados fossem robustos e generalizáveis.

% \subsection{Treino dos Modelos}\label{treino_modelos}

% Definidos os hiperparâmetros ótimos, os modelos foram treinados utilizando o conjunto de dados preparado na Seção \ref{preparacao_dados}. O treinamento foi realizado em validação cruzada de cinco \textit{folds}, utilizando a biblioteca \texttt{cuml} para se beneficiar da aceleração por GPU. Foi selecionado como modelo final aquele modelo que apresentou o melhor desempenho médio nos \textit{folds} de validação para cada variável resposta.

% \subsection{Avaliação dos Modelos}\label{avaliacao_modelos}

% A avaliação dos modelos foi realizada utilizando métricas de desempenho apropriadas para problemas de regressão, como a Raiz do Erro Quadrático Médio (RMSE) e o Coeficiente de Determinação (R²). Essas métricas fornecem uma visão clara da precisão das previsões dos modelos em relação aos valores reais das notas do ENEM.

% Também foram realizadas análises de resíduos para verificar a adequação dos modelos e identificar possíveis padrões não capturados pelas previsões, bem como a análise gráfica das previsões versus os valores reais para avaliar visualmente o desempenho dos modelos.

% \section{Magnitude da Influência das Variáveis Preditoras}\label{medicao_efeito_variaveis}

% Para medir o efeito de cada variável preditora nas notas do ENEM, foram utilizadas técnicas de interpretação de modelos, que permitem identificar quais variáveis têm maior impacto nas previsões dos modelos e como elas influenciam as notas dos estudantes. Entre as técnicas empregadas estão a importância das características (\textit{feature importance}), a análise dos valores SHAP (\textit{SHapley Additive exPlanations}) e os gráficos de dependência parcial (\textit{partial dependence plots}).

% Além disso, foi realizada uma análise de sensibilidade para avaliar como mudanças nas variáveis preditoras afetam as previsões dos modelos. Para isso, foi construída uma matriz de cenários hipotéticos, onde cada variável preditora é alterada sistematicamente enquanto as outras são mantidas constantes. As previsões resultantes foram então analisadas para quantificar o impacto de cada variável nas notas do ENEM.

% \section{Limitações e Considerações Éticas}\label{limitacoes_eticas}

% Algumas limitações devem ser destacadas. Primeiro, apesar do grande volume de dados, a presença de vieses de seleção (por exemplo, diferença entre participantes regulares e treineiros, ou entre ausentes e presentes nas provas) pode influenciar as inferências; as análises procuram mitigar esses efeitos, mas não os eliminam completamente. Segundo, variáveis censuradas, inconsistências de registro e códigos especiais para ausência exigiram tratamentos que podem introduzir perdas de informação.

% Quanto às considerações éticas, todos os dados utilizados são microdados públicos disponibilizados pelo INEP, já anonimizados para preservar a privacidade dos participantes. Recomenda-se cautela na interpretação dos resultados para evitar conclusões simplistas sobre individualidades dos estudantes ou estigmatização de grupos e instituições.

% No Capítulo \ref{cap_resultados} serão apresentados os resultados empíricos da metodologia empregada: (i) a descrição dos dados após o pré-processamento, (ii) a análise de correlação entre as variáveis preditoras, (iii) o desempenho dos modelos preditivos na previsão das notas do ENEM, e (iv) a análise da magnitude da influência das variáveis preditoras nas notas dos estudantes.